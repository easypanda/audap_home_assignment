{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f708a78",
   "metadata": {},
   "source": [
    "# Methodologie "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa970a96",
   "metadata": {},
   "source": [
    "Ce notebook a pour but de présenter la méthodologie pour récupérer les datas sur le site du BOAMP.fr concernant les données des marchés publics. Toutes les datas ont été obtenus avec l'API BOAMP (https://api.gouv.fr/les-api/boamp)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7425b58a",
   "metadata": {},
   "source": [
    "## Téléchargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3812e73c",
   "metadata": {},
   "source": [
    "### Première étape: Importer les libraries nécessaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "attended-balloon",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-12T07:05:50.062757Z",
     "start_time": "2021-04-12T07:05:49.610972Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pour le traitement des données\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Pour télécharger les données\n",
    "import requests\n",
    "\n",
    "# Autres\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Pour la géo-localisation\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584f49ef",
   "metadata": {},
   "source": [
    "### Ensuite on peut préparer le téléchargement des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mature-while",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-12T07:05:50.074946Z",
     "start_time": "2021-04-12T07:05:50.072615Z"
    }
   },
   "outputs": [],
   "source": [
    "# Le chemin où vont être télécharger les données\n",
    "path = Path().resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "silver-mounting",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-12T07:07:08.900415Z",
     "start_time": "2021-04-12T07:07:08.897320Z"
    }
   },
   "outputs": [],
   "source": [
    "# L'ensemble des paramétres qui nous intéressent\n",
    "\n",
    "dpts = ['33', '64', '65', '31'] # Département\n",
    "years = [x for x in range(2016,2022)] # Année de 2016 à 2021\n",
    "famile_cat = [\"DIVERS\",\"DSP\",\"FNS\",\"JOUE\",\"MAPA\",\"inconnu\"] # Catégorie de marché\n",
    "type_marche = [\"TRAVAUX\"] # Type de marché: Travaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "transparent-profile",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-12T07:10:29.637840Z",
     "start_time": "2021-04-12T07:07:22.937019Z"
    }
   },
   "outputs": [],
   "source": [
    "# On télécharge les ids qui nous intéressents et on les stores dans un dictionnaire.\n",
    "\n",
    "queries = {}\n",
    "\n",
    "for year in years:\n",
    "    for dpt in dpts:\n",
    "        for cat in famile_cat:\n",
    "            for typemarche in type_marche:\n",
    "                url = f\"http://api.dila.fr/opendata/api-boamp/annonces/search?criterion=\\\n",
    "                (source_cat%3Av3%20AND%20\\\n",
    "                type_marche%3A{typemarche}%20AND%20regiondepartement_cat%3A72%2F{dpt}%20AND%20dateparution%3A{year}%20AND%20famille_cat%3A{cat})\"\n",
    "                x = requests.get(url)\n",
    "                try:\n",
    "                    queries[f\"{year}_{dpt}_{cat}_{typemarche}\"] = pd.DataFrame(x.json()[\"item\"])\n",
    "                except KeyError:\n",
    "                    pass\n",
    "                \n",
    "# puis on concat le dictionnaire pour le transformer en pandas dataframe.\n",
    "id_to_download = pd.concat(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032eaa63",
   "metadata": {},
   "source": [
    "### Puis on nettoie un peu le dataframe obtenu avec les IDs qui nous intéressent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "filled-parks",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-12T07:24:46.717547Z",
     "start_time": "2021-04-12T07:24:46.693608Z"
    }
   },
   "outputs": [],
   "source": [
    "id_to_download.drop_duplicates(inplace=True) #On supprimer les values dupliquées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3b2232cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-12T07:24:48.560451Z",
     "start_time": "2021-04-12T07:24:48.555693Z"
    }
   },
   "outputs": [],
   "source": [
    "id_to_download.reset_index(inplace=True) # On reset l'index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c462e272",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-12T07:24:50.400314Z",
     "start_time": "2021-04-12T07:24:50.396212Z"
    }
   },
   "outputs": [],
   "source": [
    "# On extrait quelques données intéressantes\n",
    "\n",
    "def clean_id_data(df):\n",
    "    df[\"annee\"] = df[\"level_0\"].str.split(\"_\",expand=True)[0] # L'Année\n",
    "    df[\"dept\"] = df[\"level_0\"].str.split(\"_\",expand=True)[1] # Le département\n",
    "    df[\"cat\"] = df[\"level_0\"].str.split(\"_\",expand=True)[2] # La catégorie\n",
    "    df[\"marche\"] = df[\"level_0\"].str.split(\"_\",expand=True)[3] # Le marché\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d2dd1c90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-12T07:24:51.725053Z",
     "start_time": "2021-04-12T07:24:51.351445Z"
    }
   },
   "outputs": [],
   "source": [
    "id_to_download = clean_id_data(id_to_download) # On applique la fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "665bbb61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-12T07:25:16.989023Z",
     "start_time": "2021-04-12T07:25:16.979305Z"
    }
   },
   "outputs": [],
   "source": [
    "# On finit de nettoyer le fichier\n",
    "id_to_download = id_to_download.drop(columns=[\"level_0\",\"level_1\",\"id\"]).rename(columns={\"value\":\"gestion.reference.idweb\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "947d5d57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-12T07:25:17.943124Z",
     "start_time": "2021-04-12T07:25:17.934082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gestion.reference.idweb</th>\n",
       "      <th>schema</th>\n",
       "      <th>description</th>\n",
       "      <th>annee</th>\n",
       "      <th>dept</th>\n",
       "      <th>cat</th>\n",
       "      <th>marche</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16-157491</td>\n",
       "      <td>http://schemas.journal-officiel.gouv.fr/schema...</td>\n",
       "      <td>conception et mise en oeuvre d'une campagne de...</td>\n",
       "      <td>2016</td>\n",
       "      <td>33</td>\n",
       "      <td>DIVERS</td>\n",
       "      <td>SERVICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16-121410</td>\n",
       "      <td>http://schemas.journal-officiel.gouv.fr/schema...</td>\n",
       "      <td>appel à manifesttaion d'intérêt</td>\n",
       "      <td>2016</td>\n",
       "      <td>33</td>\n",
       "      <td>DIVERS</td>\n",
       "      <td>SERVICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16-78911</td>\n",
       "      <td>http://schemas.journal-officiel.gouv.fr/schema...</td>\n",
       "      <td>Concession (Ou Delegation) Du Service Public D...</td>\n",
       "      <td>2016</td>\n",
       "      <td>33</td>\n",
       "      <td>DSP</td>\n",
       "      <td>SERVICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16-182879</td>\n",
       "      <td>http://schemas.journal-officiel.gouv.fr/schema...</td>\n",
       "      <td>Délégation de service public du centre équestr...</td>\n",
       "      <td>2016</td>\n",
       "      <td>33</td>\n",
       "      <td>DSP</td>\n",
       "      <td>SERVICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16-90624</td>\n",
       "      <td>http://schemas.journal-officiel.gouv.fr/schema...</td>\n",
       "      <td>Délégation de service public pour la Gestion d...</td>\n",
       "      <td>2016</td>\n",
       "      <td>33</td>\n",
       "      <td>DSP</td>\n",
       "      <td>SERVICE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gestion.reference.idweb                                             schema  \\\n",
       "0               16-157491  http://schemas.journal-officiel.gouv.fr/schema...   \n",
       "1               16-121410  http://schemas.journal-officiel.gouv.fr/schema...   \n",
       "2                16-78911  http://schemas.journal-officiel.gouv.fr/schema...   \n",
       "3               16-182879  http://schemas.journal-officiel.gouv.fr/schema...   \n",
       "4                16-90624  http://schemas.journal-officiel.gouv.fr/schema...   \n",
       "\n",
       "                                         description annee dept     cat  \\\n",
       "0  conception et mise en oeuvre d'une campagne de...  2016   33  DIVERS   \n",
       "1                    appel à manifesttaion d'intérêt  2016   33  DIVERS   \n",
       "2  Concession (Ou Delegation) Du Service Public D...  2016   33     DSP   \n",
       "3  Délégation de service public du centre équestr...  2016   33     DSP   \n",
       "4  Délégation de service public pour la Gestion d...  2016   33     DSP   \n",
       "\n",
       "    marche  \n",
       "0  SERVICE  \n",
       "1  SERVICE  \n",
       "2  SERVICE  \n",
       "3  SERVICE  \n",
       "4  SERVICE  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_download.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e126112c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-12T07:25:22.560155Z",
     "start_time": "2021-04-12T07:25:22.400873Z"
    }
   },
   "outputs": [],
   "source": [
    "id_to_download.to_csv(\"./id_to_clean.csv\",index=0) # Enregistrement en .csv au cas où"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c925acd",
   "metadata": {},
   "source": [
    "### Ensuite on télécharge les données sur tous les IDs qui nous intéressent, un par un."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "beautiful-union",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T12:48:14.289028Z",
     "start_time": "2021-04-10T08:58:05.324734Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25073/25073 [3:50:08<00:00,  1.82it/s]  \n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "\n",
    "for i in tqdm(id_to_download[\"value\"].unique()):\n",
    "    url = f\"http://api.dila.fr/opendata/api-boamp/annonces/v230/{i}\"\n",
    "    y = requests.get(url)\n",
    "    data[f\"{i}\"] = y.json()\n",
    "    with open(path / f'json/{i}.txt', 'w') as outfile: # Création de json files pour chaque id pour éviter de devoir le refaire\n",
    "        json.dump(data[f\"{i}\"], outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a730f8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensuite on concat tous les fichiers json téléchargés ensemble dans un unique pandas dataframe.\n",
    "\n",
    "data = {}\n",
    "\n",
    "for x in os.listdir(path_json):\n",
    "    if x.split(\".txt\")[0] in list(id_to_download[\"value\"].unique()):\n",
    "        with open(path_json / x) as f:\n",
    "            i = json.load(f)\n",
    "            data[f\"{x.split('.txt')[0]}\"] = pd.json_normalize(i)\n",
    "            \n",
    "df = pd.concat(data)\n",
    "\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17c2536",
   "metadata": {},
   "source": [
    "### Et on enregistre le résultat final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-valentine",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./full_data.csv\",index=0) # On enregistre le fichier final."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17caa1f5",
   "metadata": {},
   "source": [
    "## Nettoyage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab24b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On merge les datas avec les id pour récupérer certaines références comme l'année, etc.\n",
    "df = df.merge(ids,on=[\"gestion.reference.idweb\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30561dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On nettoie les data en gardant uniquement les bons codes postaux\n",
    "df[\"dept\"] = df[\"donnees.identite.cp\"].astype(str).str[:2]\n",
    "dpts = ['33', '64', '65', '31']\n",
    "df = df[df[\"dept\"].isin([x for x in dpts])]\n",
    "df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25666e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour réduire le nombre de colonnes\n",
    "def concat_columns(df, regex):\n",
    "    \"\"\"\n",
    "    On passe un panda dataframe ainsi qu'un regex des colonnes que l'on souhaite réduire à une seule.\n",
    "    \"\"\"\n",
    "\n",
    "    # List des colonnes à enlever\n",
    "    col_to_drop = [x for x in df.filter(regex=regex)]\n",
    "    \n",
    "    # Concat des colonnes\n",
    "    df[regex] = df[[x for x in df.filter(regex=regex).columns]].apply(\n",
    "        lambda row: ''.join(row.values.astype(str)), axis=1)\n",
    "    \n",
    "    # Extraction des données\n",
    "    df[regex] = df[regex].str.extract(r'(<(.*).xmlns)')[1]\n",
    "    \n",
    "    # Drop des colonnes redondates.\n",
    "    df.drop(columns=col_to_drop, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db5aec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = concat_columns(df,\"donnees.procedure.typeprocedure*\")\n",
    "df = concat_columns(df,\"gestion.reference.typeavis.famille*\")\n",
    "df = concat_columns(df,\"gestion.reference.typeavis.perimetre*\")\n",
    "df = concat_columns(df,\"donnees.typeorganisme*\")\n",
    "df = concat_columns(df,\"gestion.reference.typeavis.nature.appeloffre*\")\n",
    "df = concat_columns(df,\"gestion.reference.typeavis.statut*\")\n",
    "df = concat_columns(df,\"gestion.indexation.criteressociauxenv.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9a8ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List des colonnes à enlever\n",
    "col_to_drop = [\"level_0\",\n",
    "               \"level_1\"]\n",
    "\n",
    "# On enlève aussi\n",
    "\n",
    "col_to_drop.extend(df.filter(regex=\"donnees.renseignementscomplementaires*\").columns.tolist())\n",
    "col_to_drop.extend(df.filter(regex=\"donnees.procedure*\").columns.tolist())\n",
    "col_to_drop.extend(df.filter(regex=\"donnees.conditiondelai*\").columns.tolist())\n",
    "col_to_drop.extend(df.filter(regex=\"donnees.modif*\").columns.tolist())\n",
    "col_to_drop.extend(df.filter(regex=\"donnees.rectif*\").columns.tolist())\n",
    "col_to_drop.extend(df.filter(regex=\"donnees.conditionparticipation*\").columns.tolist())\n",
    "col_to_drop.extend(df.filter(regex=\"gestion.indexation.date*\").columns.tolist())\n",
    "col_to_drop.extend(df.filter(regex=\"gestion.indexation.deppublication*\").columns.tolist())\n",
    "col_to_drop.extend(df.filter(regex=\"gestion.nomhtml*\").columns.tolist())\n",
    "\n",
    "# On enlève les colonnes avec plus de 90% de valeurs nulles\n",
    "col_to_drop.extend(df.isnull().mean().reset_index()[df.isnull().mean().reset_index()[0] > 0.90][\"index\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfde6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=col_to_drop,errors='ignore',inplace=True) # On drop les colonnes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de79a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_clean = [\"donnees.conditionrelativemarche.participationelectroniqueoui\",\n",
    "                \"donnees.identite.agitpourautrecomptenon\",\n",
    "                \"donnees.identite.organismeacheteurcentralnon\",\n",
    "                \"donnees.conditionadministrative.envoielectroniqueavecoutilnon\",\n",
    "                \"donnees.conditionrelativemarche.autresconditionspartnon\",\n",
    "                \"donnees.conditionrelativemarche.unitemonetaireeur\",\n",
    "                \"donnees.conditionadministrative.envoielectroniqueavecoutilnon\"\n",
    "               ]\n",
    "\n",
    "# On finit de nettoyer les données\n",
    "for i in col_to_clean:\n",
    "    df[i] = df[i].str.extract(r'(<(.*).xmlns)')[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84faa0fc",
   "metadata": {},
   "source": [
    "## Géolocalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab1e9c4",
   "metadata": {},
   "source": [
    "On commence par extraire et nettoyer l'adresse complète."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e3c716",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"adresse_complete\"] = df[\"donnees.identite.adresse\"].str.lower()\\\n",
    "    .str.replace(\"cedex\", \"\", regex=True)\\\n",
    "    .str.replace(r\"(cs\\s?\\d*.?)\", \"\", regex=True)\\\n",
    "    .str.replace(\"  \", \" \") \\\n",
    "    +\\\n",
    "    \", \" \\\n",
    "    + \\\n",
    "    df[\"donnees.identite.ville\"].str.lower()\\\n",
    "    .str.replace(\"cedex\", \"\", regex=True)\\\n",
    "    .str.replace(r\"(cs\\s?\\d*.?)\", \"\", regex=True)\\\n",
    "    .str.replace(\"  \", \" \")\n",
    "\n",
    "df[\"adresse_complete\"] = df[\"adresse_complete\"].str.replace(\" , \",\" \").str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4928bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisation de openstreemap pour obtenir les coordonnées gps\n",
    "geolocator = Nominatim(user_agent=\"https://nominatim.openstreetmap.org\")\n",
    "# Delay de 1s par requête pour ne pas subir de timeout\n",
    "geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1843bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boucle sur toutes les adresses\n",
    "for i in tqdm(df[\"adresse_complete\"]):\n",
    "    # Si l'on a déjà des coordonnnées GPS, on passe à l'adresse suivante\n",
    "    if df[df[\"adresse_complete\"] == i][\"latitude\"].isnull().all() == False: \n",
    "        pass\n",
    "    else:\n",
    "        try:\n",
    "            if geocode(i) is None: # Si l'adresse complète ne fonctionne pas, on essaye juste le nom de la ville\n",
    "                new_search = list(df[df[\"adresse_complete\"] == i][\"donnees.identite.ville\"].str.lower()\\\n",
    "                                   .str.replace(\"cedex\", \"\", regex=True)\\\n",
    "                                   .str.replace(r\"(cs\\s?\\d*.?)\", \"\", regex=True)\\\n",
    "                                   .str.replace(\"  \", \" \").str.title())[0]\n",
    "                location = geocode(new_search)\n",
    "                df.loc[df[\"adresse_complete\"] == i, \"latitude\"] = location.latitude \n",
    "                df.loc[df[\"adresse_complete\"] == i,\n",
    "                       \"longtitude\"] = location.longitude\n",
    "                os.sleep(1)  # On attend 1s avant de continuer\n",
    "            else:\n",
    "                location = geocode(i)\n",
    "                df.loc[df[\"adresse_complete\"] == i, \"latitude\"] = location.latitude\n",
    "                df.loc[df[\"adresse_complete\"] == i,\n",
    "                       \"longtitude\"] = location.longitude\n",
    "                os.sleep(1)  # On attend 1s avant de continuer\n",
    "        except AttributeError: # Si error, on passe\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d83208",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(path / \"data.csv\") # Puis on export les Data au format csv!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a8b276",
   "metadata": {},
   "source": [
    "## Création de la webapp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233f4782",
   "metadata": {},
   "source": [
    "Maintenant que les données ont été téléchargés, le reste du code pour la webapp est disponible sur github à l'adresse suivante:\n",
    "\n",
    "https://github.com/easypanda/audap_home_assignment/tree/main/webapp"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
